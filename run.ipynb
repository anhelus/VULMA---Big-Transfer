{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning BiT\n",
    "\n",
    "due step\n",
    "\n",
    "1. creare un nuovo modello con un nuovo layer finale (chiamato *head*)\n",
    "2. fine tuning di questo modello usando BiT-HyperRule\n",
    "\n",
    "## 1. Creazione del nuovo modello\n",
    "\n",
    "Per creare il nuovo modello:\n",
    "\n",
    "1. rimuoviamo la testa originale del modello. QUesto ci lascia con l'output prima del logits. Se usiamo un modello targato come feature extractor non dobbiamof arlo, in quanto la testa è già stata rimossa\n",
    "2. aggiungiamo una nuova testa con il numero di output uguali al numero di classi del nostro nuovo task. Notiamo che è importante inizializzare l'head a ttitti zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 12:34:29.953701: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-17 12:34:30.191715: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-17 12:34:31.248054: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-17 12:34:31.248190: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-17 12:34:31.248196: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 12:34:33.119697: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 12:34:33.243635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 12:34:33.243918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 12:34:33.244725: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-17 12:34:33.246428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 12:34:33.247065: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 12:34:33.247308: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 12:34:34.530919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 12:34:34.531461: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 12:34:34.531475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-01-17 12:34:34.531843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-17 12:34:34.531881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5396 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model_url = 'https://tfhub.dev/google/bit/m-r50x1/1'\n",
    "module = hub.KerasLayer(model_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dal momento che vogliamo usare BiT su un nuovo dataset, dobbiamo rimpiazzare il layer finale con uno che ha il corretto numero di classi in output, chiamato *head*. Le nuove head devono essere inizializzate a tutti zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES=7\n",
    "\n",
    "class MyBiTModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, num_classes, module):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.head = tf.keras.layers.Dense(num_classes, kernel_initializer='zeros')\n",
    "        self.bit_model = module\n",
    "    \n",
    "    def call(self, images):\n",
    "        bit_embedding = self.bit_model(images)\n",
    "        return self.head(bit_embedding)\n",
    "\n",
    "model = MyBiTModel(num_classes=NUM_CLASSES, module=module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing\n",
    "\n",
    "#### BiT Hyper-Rule\n",
    "\n",
    "Per il fine tuning del modello usiamo BiT HyperRule, euristica per la scelta degli iperparametri per il downstream fine-tuning. Questo non è un **hyperparameters sweep**????? dato un dataset, specifichiamo un insieme di iperparametri che abbiamo visto produrre buoni risultati. Possiamo spesso ottenere risultati migliori eseguendo un hyperparameter sweep, ma la BiT HyperRule è un modo efficace per ottenere dei buoni risultati iniziali sul dataset.\n",
    "\n",
    "##### Dettagli\n",
    "\n",
    "Nella BiT-HyperRule, usiamo un ottimizzatore SGD standard con un learning rate iniziale di $0.003$, momentum  di 0.9, e batch size di 512. Il learning rate decade di un fattore di 10 al 30%, 60% e 90% degli step di training.\n",
    "\n",
    "Per quello che riguarda il preprocessing delle immagini, queste vengono ridimensionate, si fa un crop casuale, e quindi si effettua un flip orizzontale in maniera casuale. I crop e i flip orizzontali sono casuali per tutti i task, ad eccezione di quelli dove questo tipo di azione distrugge la semantica delle label. Ovvero, non applichiamo il random crop casuale ai task dove è necessario contare oggetti, o il flip casuale orizzontale dove dobbiamo predire l'orientamento di un oggetto.\n",
    "\n",
    "| Dimensione dell'immagine | Ridimensionamento | Dimensioni random crop |\n",
    "\n",
    "| -  | - | - |\n",
    "\n",
    "| Minore di $96 \\times 96 | $160 \\times 160$ | $128 \\times 128$ |\n",
    "\n",
    "| Maggiore o uguale di $96 \\times 96$ | $512 \\times 512$ | $480 \\times 480$ | \n",
    "\n",
    "NEl caso il dataset abbia più di 20.000 campioni, usiamo MixUp. \n",
    "\n",
    "\n",
    "#### iperparametri del datset\n",
    "\n",
    "Impostiamo gli iperparametri dipendenti dal dataset. Ad esempio, il nostro dataset ha XXX immagini di dimensione variabile (alcune centinaia di pixel per alcune centinai adi pixel), per cui le dimensioni dell'immagini sono maggiori di 96x96 e la dimensione del dataset è inferiore a 20k. TUttavia, per ragioni di velocità, potremmo decidere di addestrarci su immagini a risoluzione inferiore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4281100.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    CROP_TO 480\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "RESIZE_TO = 512\n",
    "CROP_TO = 480\n",
    "BATCH_SIZE=512\n",
    "SCHEDULE_LENGTH = 500\n",
    "SCHEDULE_BOUNDARIES = [200, 300, 400]\n",
    "SCHEDULE_LENGTH = SCHEDULE_LENGTH * 512 / BATCH_SIZE\n",
    "lr = 0.003 * BATCH_SIZE / 512\n",
    "STEPS_PER_EPOCH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per questioni di performance possiamo cambiare BATCH_SIZE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_Train(features):\n",
    "    # random crops\n",
    "    features['image'] = tf.image.random_flip_left_right(features['image'])\n",
    "    features['image'] = tf.image.resize(features['image'], [RESIZE_TO, RESIZE_TO])\n",
    "    features['image'] = tf.image.random_crop(features['image'], [CROP_TO, CROP_TO, 3])\n",
    "    features['image'] = tf.cast(features['image'], tf.float32) / 255.0\n",
    "    return features\n",
    "\n",
    "def preprocess_test(features):\n",
    "    features['image'] = tf.image.resize(features['image'], [RESIZE_TO, RESIZE_TO])\n",
    "    features['image'] = tf.cast(features['image'], tf.float32) / 255.0\n",
    "    return features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "14235179db2d558d1dbf63af07be1d02a7c5a199947a8102f341d92f0d7d0f07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
